# Data Model

**Feature**: Qdrant Embeddings Ingestion Pipeline
**Date**: 2025-12-11

## Overview

This document defines all data entities, their attributes, relationships, and transformations throughout the ingestion pipeline.

## Entity Definitions

### 1. URL (Sitemap Entry)

Represents a discovered URL from the sitemap.

**Attributes**:
- `url`: string - Full URL (e.g., "https://physical-ai-humanoid-robotics-blond-eta.vercel.app/docs/intro")
- `processed`: boolean - Whether this URL has been ingested
- `last_crawled`: ISO 8601 timestamp - When this URL was last processed

**Source**: Parsed from sitemap.xml `<loc>` elements

**Lifecycle**:
1. Discovered during sitemap parsing
2. Checked against Qdrant for existing chunks
3. Marked as processed after successful ingestion

**Example**:
```json
{
  "url": "https://physical-ai-humanoid-robotics-blond-eta.vercel.app/docs/chapter1/intro",
  "processed": true,
  "last_crawled": "2025-12-11T10:30:00Z"
}
```

---

### 2. Page (Crawled Content)

Represents the extracted content from a single web page.

**Attributes**:
- `url`: string - Source URL
- `title`: string - Page title (from `<title>` or `<h1>`)
- `content`: string - Extracted main text content
- `word_count`: integer - Number of words in content
- `token_count`: integer - Number of tokens (tiktoken)
- `crawled_at`: ISO 8601 timestamp - When page was fetched

**Source**: HTML fetched via HTTP GET, parsed with BeautifulSoup

**Extraction Rules**:
- Extract from `<article>` or `<main>` tag
- Exclude: navigation, sidebar, footer, pagination
- Preserve: headings, paragraphs, lists, code blocks
- Clean: remove extra whitespace, normalize line breaks

**Validation**:
- Content length > 100 characters (filter empty pages)
- Token count < 100,000 (detect malformed extractions)

**Example**:
```json
{
  "url": "https://physical-ai-humanoid-robotics-blond-eta.vercel.app/docs/chapter1/intro",
  "title": "Introduction to Humanoid Robotics",
  "content": "Humanoid robotics focuses on creating robots with human-like form...",
  "word_count": 1523,
  "token_count": 2145,
  "crawled_at": "2025-12-11T10:30:15Z"
}
```

---

### 3. Chunk (Text Segment)

Represents a tokenized segment of page content with overlap.

**Attributes**:
- `chunk_id`: string (UUID v4) - Unique identifier for this chunk
- `text`: string - Chunk content (300-500 tokens)
- `token_count`: integer - Exact token count
- `source_url`: string - Origin page URL
- `chunk_index`: integer - Position within page (0-indexed)
- `page_title`: string - Title of source page
- `start_token`: integer - Starting token position in original text
- `end_token`: integer - Ending token position in original text

**Generation Logic**:
- Tokenize full page content
- Sliding window: 400 tokens (target), 30 tokens overlap
- Decode tokens back to text for each chunk
- Generate UUID for each chunk

**Constraints**:
- 300 ≤ token_count ≤ 500
- Chunks from same page have consecutive chunk_index values
- Overlap ensures no semantic boundaries lost

**Example**:
```json
{
  "chunk_id": "a7f3e9b1-4c2d-4e8a-9f1b-2d3c4e5f6a7b",
  "text": "Humanoid robotics focuses on creating robots with human-like form and function. These robots typically have a head, torso, two arms, and two legs...",
  "token_count": 395,
  "source_url": "https://physical-ai-humanoid-robotics-blond-eta.vercel.app/docs/chapter1/intro",
  "chunk_index": 0,
  "page_title": "Introduction to Humanoid Robotics",
  "start_token": 0,
  "end_token": 395
}
```

---

### 4. Embedding (Vector Representation)

Represents the semantic vector for a chunk generated by Cohere.

**Attributes**:
- `vector`: float[] - Embedding vector (1024 dimensions)
- `model`: string - Model identifier (e.g., "embed-english-v3.0")
- `input_type`: string - Cohere input type ("search_document")
- `created_at`: ISO 8601 timestamp - When embedding was generated

**Source**: Cohere Embed API response

**Properties**:
- Vector length: 1024 (fixed)
- Values: float32, typically normalized to unit length
- Model version pinned for consistency

**API Contract**:
```python
response = cohere_client.embed(
    texts=[chunk['text']],
    model='embed-english-v3.0',
    input_type='search_document'
)
embedding = response.embeddings[0]  # list[float] with 1024 elements
```

**Example**:
```json
{
  "vector": [0.023, -0.145, 0.892, ..., 0.034],
  "model": "embed-english-v3.0",
  "input_type": "search_document",
  "created_at": "2025-12-11T10:31:05Z"
}
```

---

### 5. QdrantPoint (Stored Vector with Metadata)

Represents the final document stored in Qdrant collection.

**Attributes**:
- `id`: string (UUID) - Unique point ID (same as chunk_id)
- `vector`: float[] - Embedding vector (1024 dimensions)
- `payload`: object - Metadata for filtering and display
  - `text`: string - Original chunk text
  - `url`: string - Source page URL
  - `chunk_index`: integer - Position in page
  - `page_title`: string - Source page title
  - `token_count`: integer - Token count
  - `created_at`: string - Ingestion timestamp

**Storage Format**: Qdrant's internal binary format (optimized for similarity search)

**Indexing**: HNSW graph index for approximate nearest neighbor search

**Example**:
```python
from qdrant_client.models import PointStruct

point = PointStruct(
    id="a7f3e9b1-4c2d-4e8a-9f1b-2d3c4e5f6a7b",
    vector=[0.023, -0.145, 0.892, ..., 0.034],
    payload={
        "text": "Humanoid robotics focuses on creating robots...",
        "url": "https://physical-ai-humanoid-robotics-blond-eta.vercel.app/docs/chapter1/intro",
        "chunk_index": 0,
        "page_title": "Introduction to Humanoid Robotics",
        "token_count": 395,
        "created_at": "2025-12-11T10:31:10Z"
    }
)
```

---

## Relationships

```
Sitemap (XML)
   │
   ├─ contains N URLs
   │
   ▼
URL (1)
   │
   ├─ fetched as
   │
   ▼
Page (1)
   │
   ├─ split into N Chunks
   │
   ▼
Chunk (N)
   │
   ├─ embedded via Cohere
   │
   ▼
Embedding (N)
   │
   ├─ stored as
   │
   ▼
QdrantPoint (N)
```

**Cardinality**:
- 1 Sitemap → 50-200 URLs (estimated)
- 1 URL → 1 Page (one-to-one)
- 1 Page → 5-25 Chunks (depends on content length)
- 1 Chunk → 1 Embedding (one-to-one)
- 1 Embedding → 1 QdrantPoint (one-to-one)

**Total Scale**: ~1000-5000 QdrantPoints for full textbook

---

## Data Flow

### Stage 1: Discovery
```
Sitemap XML → Parse → List[URL]
```
**Input**: https://physical-ai-humanoid-robotics-blond-eta.vercel.app/sitemap.xml
**Output**: List of 50-200 URLs
**Error Handling**: Fail fast if sitemap unreachable (critical)

### Stage 2: Crawling
```
URL → HTTP GET → HTML → BeautifulSoup → Page
```
**For Each URL**:
1. Send HTTP GET request
2. Parse HTML with BeautifulSoup
3. Extract title and main content
4. Validate content length
5. Create Page entity

**Error Handling**: Log and skip on 404/500, continue to next URL

### Stage 3: Chunking
```
Page.content → Tokenize → Sliding Window → List[Chunk]
```
**For Each Page**:
1. Tokenize full text (tiktoken)
2. Apply sliding window (400 tokens, 30 overlap)
3. Decode tokens to text
4. Generate chunk_id (UUID)
5. Attach metadata (URL, title, index)

**Error Handling**: Skip page if tokenization fails

### Stage 4: Embedding
```
List[Chunk] → Batch → Cohere API → List[Embedding]
```
**For Each Batch** (96 chunks):
1. Extract chunk texts
2. Call Cohere embed API
3. Receive 1024-dimensional vectors
4. Validate vector dimensions
5. Pair embeddings with chunks

**Error Handling**: Retry 3x with exponential backoff, skip batch on failure

### Stage 5: Storage
```
(Chunk, Embedding) → QdrantPoint → Qdrant.upsert → Stored
```
**For Each Point**:
1. Create PointStruct with ID, vector, payload
2. Batch upsert to Qdrant (100 points)
3. Verify upload success

**Error Handling**: Retry upsert on transient failures, log permanent failures

---

## Validation Rules

### URL Validation
- Must start with https://physical-ai-humanoid-robotics-blond-eta.vercel.app/
- Must not be duplicate in sitemap
- Must return 200 status code

### Page Validation
- Content length: 100 < characters < 1,000,000
- Token count: 50 < tokens < 100,000
- Title: not empty, < 500 characters

### Chunk Validation
- Token count: 300 ≤ tokens ≤ 500
- Text: not empty, valid UTF-8
- chunk_index: 0 ≤ index < 1000 (per page)

### Embedding Validation
- Vector dimensions: exactly 1024
- Vector values: all finite floats
- Model: matches expected "embed-english-v3.0"

### QdrantPoint Validation
- ID: valid UUID v4
- Vector: 1024 dimensions, all finite
- Payload: all required fields present (text, url, chunk_index, page_title, token_count, created_at)

---

## State Management

### Idempotency Mechanism

**Question**: "Has this URL already been processed?"

**Implementation**: Query Qdrant for existing points with matching URL

```python
from qdrant_client.models import Filter, FieldCondition, MatchValue

def is_url_processed(qdrant_client, collection_name, url):
    result = qdrant_client.scroll(
        collection_name=collection_name,
        scroll_filter=Filter(
            must=[
                FieldCondition(
                    key="url",
                    match=MatchValue(value=url)
                )
            ]
        ),
        limit=1
    )
    return len(result[0]) > 0
```

**Behavior**:
- If points exist: Skip URL, log "Already processed"
- If no points: Process URL normally

**Re-ingestion**: To re-process a URL, manually delete its points from Qdrant first.

---

## Storage Schema

### Qdrant Collection Configuration

**Collection Name**: `rag_embedding`

**Vector Config**:
- Size: 1024
- Distance: Cosine

**Payload Schema** (indexed fields):
- `url`: keyword (exact match filtering)
- `chunk_index`: integer (range filtering)
- `token_count`: integer (range filtering)
- `page_title`: text (full-text search)
- `created_at`: datetime (time-range filtering)
- `text`: not indexed (display only, too large)

**Indexes**:
- HNSW graph for vector similarity
- Payload indexes for metadata filtering

**Storage Estimate**:
- 5000 points × 1024 dimensions × 4 bytes/float ≈ 20 MB vectors
- 5000 points × 500 bytes/payload ≈ 2.5 MB metadata
- Total: ~25 MB (well within 1 GB free tier)

---

## Query Patterns (Future - Retrieval Phase)

**Not implemented in this feature**, but data model supports:

### 1. Similarity Search
```python
results = qdrant_client.search(
    collection_name="rag_embedding",
    query_vector=query_embedding,
    limit=5
)
```

### 2. Filtered Search
```python
results = qdrant_client.search(
    collection_name="rag_embedding",
    query_vector=query_embedding,
    query_filter=Filter(
        must=[
            FieldCondition(
                key="url",
                match=MatchValue(value="https://example.com/specific-page")
            )
        ]
    ),
    limit=5
)
```

### 3. Metadata-Only Query
```python
results = qdrant_client.scroll(
    collection_name="rag_embedding",
    scroll_filter=Filter(
        must=[
            FieldCondition(
                key="token_count",
                range={"gte": 400, "lte": 500}
            )
        ]
    )
)
```

---

## Data Lineage

**Tracking**: Each QdrantPoint includes `created_at` timestamp for ingestion time tracking.

**Versioning**: Not implemented in Phase 1. Future: Add `version` field to payload for re-ingestion tracking.

**Audit Trail**: Pipeline logs include:
- URLs processed/skipped
- Chunks created per page
- Embeddings generated (total count)
- Points uploaded to Qdrant
- Errors and retries

---

## Performance Considerations

### Memory Usage
- Full page content: ~1-10 KB per page
- Chunks: ~1-3 KB per chunk × 5-25 chunks/page
- Embeddings: 4 KB per chunk (1024 floats × 4 bytes)
- Peak memory: ~500 MB for batch processing (96 chunks × 4 KB + overhead)

### Network Bandwidth
- Page fetches: ~10-50 KB per page
- Cohere API: Upload ~96 KB per batch, receive ~400 KB
- Qdrant upload: ~500 KB per 100-point batch

### Processing Time (Estimated)
- Sitemap parsing: <1 second
- Page crawling: ~1 second per page (sequential)
- Chunking: <100ms per page
- Embedding: ~2 seconds per 96-chunk batch
- Qdrant upload: ~500ms per 100-point batch
- **Total**: ~15-30 minutes for 200 pages

---

## Appendix: JSON Schema Examples

### Chunk Schema
```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "chunk_id": {"type": "string", "format": "uuid"},
    "text": {"type": "string", "minLength": 100},
    "token_count": {"type": "integer", "minimum": 300, "maximum": 500},
    "source_url": {"type": "string", "format": "uri"},
    "chunk_index": {"type": "integer", "minimum": 0},
    "page_title": {"type": "string"},
    "start_token": {"type": "integer", "minimum": 0},
    "end_token": {"type": "integer", "minimum": 0}
  },
  "required": ["chunk_id", "text", "token_count", "source_url", "chunk_index", "page_title"]
}
```

### QdrantPoint Payload Schema
```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "text": {"type": "string"},
    "url": {"type": "string", "format": "uri"},
    "chunk_index": {"type": "integer", "minimum": 0},
    "page_title": {"type": "string"},
    "token_count": {"type": "integer", "minimum": 300, "maximum": 500},
    "created_at": {"type": "string", "format": "date-time"}
  },
  "required": ["text", "url", "chunk_index", "page_title", "token_count", "created_at"]
}
```
